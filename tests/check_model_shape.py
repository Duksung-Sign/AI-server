import torch

MODEL_PATH = "model/250904_best_ctc_transformer_244.pt"  # ê²½ë¡œë¥¼ í•„ìš”ì— ë”°ë¼ ìˆ˜ì •í•˜ì„¸ìš”


def check_model_layers(model_path):
    checkpoint = torch.load(model_path, map_location='cpu')

    print("ðŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ!")

    if "model_state_dict" not in checkpoint:
        print("âŒ model_state_dictê°€ ì²´í¬í¬ì¸íŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")
        return

    state_dict = checkpoint["model_state_dict"]
    print(f"ðŸ” ì €ìž¥ëœ íŒŒë¼ë¯¸í„° ìˆ˜: {len(state_dict)}")

    transformer_layers = [
        k for k in state_dict.keys() if k.startswith("transformer_encoder.layers")
    ]

    # ë ˆì´ì–´ ì¸ë±ìŠ¤ ì¶”ì¶œ
    layer_indices = sorted(set(
        int(k.split('.')[2]) for k in transformer_layers
    ))

    print(f"ðŸ§± Transformer ë ˆì´ì–´ ê°œìˆ˜: {len(layer_indices)}")
    print("ðŸ“‘ ë ˆì´ì–´ ì¸ë±ìŠ¤ ëª©ë¡:", layer_indices)

    # ìƒì„¸ ì¶œë ¥
    print("\nðŸ“‹ ì£¼ìš” í‚¤ (ì¼ë¶€ë§Œ ì¶œë ¥):")
    for k in list(state_dict.keys())[:10]:
        print("  ", k)
    if len(state_dict) > 10:
        print("  ...")


if __name__ == "__main__":
    check_model_layers(MODEL_PATH)
